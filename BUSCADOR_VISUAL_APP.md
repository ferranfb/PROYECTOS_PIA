# üñºÔ∏è Buscador Visual por Similitud (Proyecto Final)

Este proyecto es una aplicaci√≥n web que permite realizar b√∫squedas visuales por similitud dentro de un repositorio de im√°genes local. La b√∫squeda se puede realizar de dos maneras:
1.  **Por Imagen:** Subiendo una imagen de consulta.
2.  **Por Texto:** Escribiendo una descripci√≥n (ej: "un perro corriendo").

## üéØ Objetivo

El objetivo es implementar un sistema que utiliza **embeddings** (vectores de IA) para encontrar las im√°genes m√°s similares (b√∫squeda *Top-K*) y mostrar los resultados en una interfaz gr√°fica con su puntuaci√≥n (*score*) de similitud.

## üõ†Ô∏è Pila Tecnol√≥gica (Tecnolog√≠as Usadas)

* **Modelo de IA (Embeddings):** `openai/clip-vit-base-patch32` (de Hugging Face). Elegida a dedo per Rafa
* **¬øQu√© es?** FAISS (Facebook AI Similarity Search) no es una base de datos tradicional (como SQL). Es una librer√≠a especializada y optimizada √∫nicamente para almacenar y buscar **vectores** de alta dimensi√≥n (como nuestros embeddings de 512 dimensiones).
    * **¬øPor qu√© la elegimos?** Se eligi√≥ por dos razones clave:
        1.  **Velocidad Extrema:** Est√° dise√±ada para comparar millones de vectores en milisegundos. Es mucho m√°s r√°pida que una b√∫squeda manual.
        2.  **Integraci√≥n:** Funciona perfectamente en Python y se integra de forma nativa con `Numpy`, facilitando el flujo de trabajo con los embeddings generados por PyTorch/CLIP.
* **Base de Datos Vectorial:** `FAISS` (de Facebook AI). Se utiliza para almacenar los miles de vectores de imagen y realizar b√∫squedas de similitud (`K-Nearest Neighbors`) de forma ultrarr√°pida.
* **Interfaz de Usuario (UI):** `Streamlit`. Permite crear una aplicaci√≥n web interactiva usando √∫nicamente c√≥digo Python, ideal para prototipar r√°pido.
* **Librer√≠as de Python:** `PyTorch`, `Transformers` (para cargar CLIP), `Numpy` (para manejo de vectores) y `Pillow` (para im√°genes).

## üöÄ C√≥mo Ejecutar Localmente (Para la Demo)

Para ejecutar el proyecto en local, solo se necesitan estos pasos:

```bash
# 1. Crear un entorno virtual (ej: venv_proyecto) y activarlo
python -m venv venv_proyecto
.\venv_proyecto\Scripts\activate

# 2. Instalar las dependencias necesarias
pip install streamlit numpy Pillow faiss-cpu torch transformers

# 3. (Paso OBLIGATORIO) Indexar las im√°genes de la carpeta /assets
# Esto crea los archivos faiss_index.bin y image_paths.npy
python indexarembeddings.py

# 4. Ejecutar la aplicaci√≥n web
streamlit run buscadorvisual_app.py

```

## Busqueda por Imagen (Score Alto)Qu√© ocurre: Cuando subes una foto (ej: un perro espec√≠fico), est√°s comparando una instancia espec√≠fica contra otras instancias espec√≠ficas (las fotos de la base de datos).
Resultado: El modelo encuentra im√°genes muy similares (ej: otros perros de la misma raza o en la misma postura). Como el parecido es tan concreto y detallado, el score de similitud es alto (ej: 0.70 - 0.85).

## B√∫squeda por Texto (Score Bajo)Qu√© ocurre: Cuando escribes "perro", est√°s comparando un concepto general y abstracto contra instancias espec√≠ficas (las fotos).
Resultado: El modelo CLIP entiende que la palabra "perro" es un "promedio" de todos los perros posibles (diferentes razas, colores, posturas). Por lo tanto, la similitud entre el concepto de "perro" 
y una foto espec√≠fica de un perro siempre ser√° matem√°ticamente menor que la similitud entre dos fotos espec√≠ficas.

## Conclusi√≥n: Un score bajo (ej: 0.23 - 0.27) no significa que la b√∫squeda haya fallado. Significa que es la mejor coincidencia para un concepto general, y es la forma correcta en que el modelo funciona.

